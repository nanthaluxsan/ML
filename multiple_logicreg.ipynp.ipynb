{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"D:/extra/udemy_machine/classification/Classification+preprocessed+data+Python.csv\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>air_qual</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>parks</th>\n",
       "      <th>Sold</th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>airport_YES</th>\n",
       "      <th>waterbody_Lake</th>\n",
       "      <th>waterbody_Lake and River</th>\n",
       "      <th>waterbody_River</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.528854</td>\n",
       "      <td>41.136779</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>21.544466</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>7.899767</td>\n",
       "      <td>12.864050</td>\n",
       "      <td>39.187747</td>\n",
       "      <td>0.054454</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>3.795104</td>\n",
       "      <td>0.551383</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.140316</td>\n",
       "      <td>0.361660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.182176</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>1.464939</td>\n",
       "      <td>2.688778</td>\n",
       "      <td>12.497221</td>\n",
       "      <td>0.010632</td>\n",
       "      <td>0.498422</td>\n",
       "      <td>2.105859</td>\n",
       "      <td>0.497845</td>\n",
       "      <td>0.394028</td>\n",
       "      <td>0.347659</td>\n",
       "      <td>0.480957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.460000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.268000</td>\n",
       "      <td>10.057600</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.033292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.127500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.025000</td>\n",
       "      <td>35.190000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>6.659000</td>\n",
       "      <td>11.189800</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.046464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.100625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.200000</td>\n",
       "      <td>39.690000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>20.950000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>7.963000</td>\n",
       "      <td>12.720000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.053507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.207500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>9.076000</td>\n",
       "      <td>14.170800</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.061397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.187500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>57.740000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>10.876000</td>\n",
       "      <td>46.198560</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.086711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.127500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            price  resid_area    air_qual    room_num         age    teachers  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    22.528854   41.136779    0.554695    6.284634   68.574901   21.544466   \n",
       "std      9.182176    6.860353    0.115878    0.702617   28.148861    2.164946   \n",
       "min      5.000000   30.460000    0.385000    3.561000    2.900000   18.000000   \n",
       "25%     17.025000   35.190000    0.449000    5.885500   45.025000   19.800000   \n",
       "50%     21.200000   39.690000    0.538000    6.208500   77.500000   20.950000   \n",
       "75%     25.000000   48.100000    0.624000    6.623500   94.075000   22.600000   \n",
       "max     50.000000   57.740000    0.871000    8.780000  100.000000   27.400000   \n",
       "\n",
       "        poor_prop  n_hos_beds  n_hot_rooms    rainfall       parks  \\\n",
       "count  506.000000  506.000000   506.000000  506.000000  506.000000   \n",
       "mean    12.653063    7.899767    12.864050   39.187747    0.054454   \n",
       "std      7.141062    1.464939     2.688778   12.497221    0.010632   \n",
       "min      1.730000    5.268000    10.057600    6.000000    0.033292   \n",
       "25%      6.950000    6.659000    11.189800   28.000000    0.046464   \n",
       "50%     11.360000    7.963000    12.720000   39.000000    0.053507   \n",
       "75%     16.955000    9.076000    14.170800   50.000000    0.061397   \n",
       "max     37.970000   10.876000    46.198560   60.000000    0.086711   \n",
       "\n",
       "             Sold    avg_dist  airport_YES  waterbody_Lake  \\\n",
       "count  506.000000  506.000000   506.000000      506.000000   \n",
       "mean     0.454545    3.795104     0.551383        0.191700   \n",
       "std      0.498422    2.105859     0.497845        0.394028   \n",
       "min      0.000000    1.127500     0.000000        0.000000   \n",
       "25%      0.000000    2.100625     0.000000        0.000000   \n",
       "50%      0.000000    3.207500     1.000000        0.000000   \n",
       "75%      1.000000    5.187500     1.000000        0.000000   \n",
       "max      1.000000   12.127500     1.000000        1.000000   \n",
       "\n",
       "       waterbody_Lake and River  waterbody_River  \n",
       "count                506.000000       506.000000  \n",
       "mean                   0.140316         0.361660  \n",
       "std                    0.347659         0.480957  \n",
       "min                    0.000000         0.000000  \n",
       "25%                    0.000000         0.000000  \n",
       "50%                    0.000000         0.000000  \n",
       "75%                    0.000000         1.000000  \n",
       "max                    1.000000         1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.loc[:,df.columns!='Sold']#independent variable two dimension so we us[[]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>air_qual</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>parks</th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>airport_YES</th>\n",
       "      <th>waterbody_Lake</th>\n",
       "      <th>waterbody_Lake and River</th>\n",
       "      <th>waterbody_River</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>32.31</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>24.7</td>\n",
       "      <td>4.98</td>\n",
       "      <td>5.480</td>\n",
       "      <td>11.19200</td>\n",
       "      <td>23</td>\n",
       "      <td>0.049347</td>\n",
       "      <td>4.0875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>22.2</td>\n",
       "      <td>9.14</td>\n",
       "      <td>7.332</td>\n",
       "      <td>12.17280</td>\n",
       "      <td>42</td>\n",
       "      <td>0.046146</td>\n",
       "      <td>4.9675</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>4.03</td>\n",
       "      <td>7.394</td>\n",
       "      <td>46.19856</td>\n",
       "      <td>38</td>\n",
       "      <td>0.045764</td>\n",
       "      <td>4.9675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "      <td>32.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>21.3</td>\n",
       "      <td>2.94</td>\n",
       "      <td>9.268</td>\n",
       "      <td>11.26720</td>\n",
       "      <td>45</td>\n",
       "      <td>0.047151</td>\n",
       "      <td>6.0650</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "      <td>32.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>21.3</td>\n",
       "      <td>5.33</td>\n",
       "      <td>8.824</td>\n",
       "      <td>11.28960</td>\n",
       "      <td>55</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>6.0625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  resid_area  air_qual  room_num   age  teachers  poor_prop  \\\n",
       "0   24.0       32.31     0.538     6.575  65.2      24.7       4.98   \n",
       "1   21.6       37.07     0.469     6.421  78.9      22.2       9.14   \n",
       "2   34.7       37.07     0.469     7.185  61.1      22.2       4.03   \n",
       "3   33.4       32.18     0.458     6.998  45.8      21.3       2.94   \n",
       "4   36.2       32.18     0.458     7.147  54.2      21.3       5.33   \n",
       "\n",
       "   n_hos_beds  n_hot_rooms  rainfall     parks  avg_dist  airport_YES  \\\n",
       "0       5.480     11.19200        23  0.049347    4.0875            1   \n",
       "1       7.332     12.17280        42  0.046146    4.9675            0   \n",
       "2       7.394     46.19856        38  0.045764    4.9675            0   \n",
       "3       9.268     11.26720        45  0.047151    6.0650            1   \n",
       "4       8.824     11.28960        55  0.039474    6.0625            0   \n",
       "\n",
       "   waterbody_Lake  waterbody_Lake and River  waterbody_River  \n",
       "0               0                         0                1  \n",
       "1               1                         0                0  \n",
       "2               0                         0                0  \n",
       "3               1                         0                0  \n",
       "4               1                         0                0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Sold, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lrs=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lrs.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24635709, -0.01729752, -0.11019455,  0.86260903, -0.00599865,\n",
       "         0.22819614, -0.21021829,  0.18006652, -0.09086611, -0.00704704,\n",
       "        -0.00499205, -0.32611303, -0.105213  , -0.09487407, -0.01512373,\n",
       "         0.20180456]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lrs.coef_ #(Beta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01671289])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lrs.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cons=sn.add_constant(x)  #without constan Bet0=0 so add constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>price</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>air_qual</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>parks</th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>airport_YES</th>\n",
       "      <th>waterbody_Lake</th>\n",
       "      <th>waterbody_Lake and River</th>\n",
       "      <th>waterbody_River</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.31</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>24.7</td>\n",
       "      <td>4.98</td>\n",
       "      <td>5.480</td>\n",
       "      <td>11.19200</td>\n",
       "      <td>23</td>\n",
       "      <td>0.049347</td>\n",
       "      <td>4.0875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>22.2</td>\n",
       "      <td>9.14</td>\n",
       "      <td>7.332</td>\n",
       "      <td>12.17280</td>\n",
       "      <td>42</td>\n",
       "      <td>0.046146</td>\n",
       "      <td>4.9675</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>4.03</td>\n",
       "      <td>7.394</td>\n",
       "      <td>46.19856</td>\n",
       "      <td>38</td>\n",
       "      <td>0.045764</td>\n",
       "      <td>4.9675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33.4</td>\n",
       "      <td>32.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>21.3</td>\n",
       "      <td>2.94</td>\n",
       "      <td>9.268</td>\n",
       "      <td>11.26720</td>\n",
       "      <td>45</td>\n",
       "      <td>0.047151</td>\n",
       "      <td>6.0650</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>36.2</td>\n",
       "      <td>32.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>21.3</td>\n",
       "      <td>5.33</td>\n",
       "      <td>8.824</td>\n",
       "      <td>11.28960</td>\n",
       "      <td>55</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>6.0625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   const  price  resid_area  air_qual  room_num   age  teachers  poor_prop  \\\n",
       "0    1.0   24.0       32.31     0.538     6.575  65.2      24.7       4.98   \n",
       "1    1.0   21.6       37.07     0.469     6.421  78.9      22.2       9.14   \n",
       "2    1.0   34.7       37.07     0.469     7.185  61.1      22.2       4.03   \n",
       "3    1.0   33.4       32.18     0.458     6.998  45.8      21.3       2.94   \n",
       "4    1.0   36.2       32.18     0.458     7.147  54.2      21.3       5.33   \n",
       "\n",
       "   n_hos_beds  n_hot_rooms  rainfall     parks  avg_dist  airport_YES  \\\n",
       "0       5.480     11.19200        23  0.049347    4.0875            1   \n",
       "1       7.332     12.17280        42  0.046146    4.9675            0   \n",
       "2       7.394     46.19856        38  0.045764    4.9675            0   \n",
       "3       9.268     11.26720        45  0.047151    6.0650            1   \n",
       "4       8.824     11.28960        55  0.039474    6.0625            0   \n",
       "\n",
       "   waterbody_Lake  waterbody_Lake and River  waterbody_River  \n",
       "0               0                         0                1  \n",
       "1               1                         0                0  \n",
       "2               0                         0                0  \n",
       "3               1                         0                0  \n",
       "4               1                         0                0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.discrete.discrete_model as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.556433\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "logit=sn.Logit(y,x_cons).fit() #add constant term in to variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Sold</td>       <th>  No. Observations:  </th>  <td>   506</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   489</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    16</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 19 Nov 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.1924</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>08:49:12</td>     <th>  Log-Likelihood:    </th> <td> -281.56</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -348.64</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>9.930e-21</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                    <td>   -2.1383</td> <td>    2.649</td> <td>   -0.807</td> <td> 0.420</td> <td>   -7.331</td> <td>    3.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price</th>                    <td>   -0.2741</td> <td>    0.033</td> <td>   -8.313</td> <td> 0.000</td> <td>   -0.339</td> <td>   -0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resid_area</th>               <td>    0.0192</td> <td>    0.027</td> <td>    0.720</td> <td> 0.471</td> <td>   -0.033</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>air_qual</th>                 <td>   -7.4183</td> <td>    2.691</td> <td>   -2.757</td> <td> 0.006</td> <td>  -12.693</td> <td>   -2.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>room_num</th>                 <td>    1.1067</td> <td>    0.277</td> <td>    4.001</td> <td> 0.000</td> <td>    0.565</td> <td>    1.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                      <td>   -0.0020</td> <td>    0.007</td> <td>   -0.302</td> <td> 0.762</td> <td>   -0.015</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>teachers</th>                 <td>    0.3150</td> <td>    0.064</td> <td>    4.937</td> <td> 0.000</td> <td>    0.190</td> <td>    0.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>poor_prop</th>                <td>   -0.2077</td> <td>    0.034</td> <td>   -6.149</td> <td> 0.000</td> <td>   -0.274</td> <td>   -0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_hos_beds</th>               <td>    0.1760</td> <td>    0.071</td> <td>    2.467</td> <td> 0.014</td> <td>    0.036</td> <td>    0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_hot_rooms</th>              <td>   -0.0742</td> <td>    0.052</td> <td>   -1.439</td> <td> 0.150</td> <td>   -0.175</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rainfall</th>                 <td>   -0.0033</td> <td>    0.008</td> <td>   -0.394</td> <td> 0.693</td> <td>   -0.020</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>parks</th>                    <td>   29.1089</td> <td>   24.177</td> <td>    1.204</td> <td> 0.229</td> <td>  -18.277</td> <td>   76.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_dist</th>                 <td>   -0.4017</td> <td>    0.098</td> <td>   -4.118</td> <td> 0.000</td> <td>   -0.593</td> <td>   -0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>airport_YES</th>              <td>   -0.1524</td> <td>    0.211</td> <td>   -0.723</td> <td> 0.469</td> <td>   -0.565</td> <td>    0.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterbody_Lake</th>           <td>   -0.1032</td> <td>    0.304</td> <td>   -0.340</td> <td> 0.734</td> <td>   -0.698</td> <td>    0.492</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterbody_Lake and River</th> <td>   -0.0626</td> <td>    0.328</td> <td>   -0.191</td> <td> 0.849</td> <td>   -0.705</td> <td>    0.580</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterbody_River</th>          <td>    0.2394</td> <td>    0.256</td> <td>    0.937</td> <td> 0.349</td> <td>   -0.262</td> <td>    0.740</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                   Sold   No. Observations:                  506\n",
       "Model:                          Logit   Df Residuals:                      489\n",
       "Method:                           MLE   Df Model:                           16\n",
       "Date:                Sat, 19 Nov 2022   Pseudo R-squ.:                  0.1924\n",
       "Time:                        08:49:12   Log-Likelihood:                -281.56\n",
       "converged:                       True   LL-Null:                       -348.64\n",
       "Covariance Type:            nonrobust   LLR p-value:                 9.930e-21\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "const                       -2.1383      2.649     -0.807      0.420      -7.331       3.054\n",
       "price                       -0.2741      0.033     -8.313      0.000      -0.339      -0.209\n",
       "resid_area                   0.0192      0.027      0.720      0.471      -0.033       0.071\n",
       "air_qual                    -7.4183      2.691     -2.757      0.006     -12.693      -2.144\n",
       "room_num                     1.1067      0.277      4.001      0.000       0.565       1.649\n",
       "age                         -0.0020      0.007     -0.302      0.762      -0.015       0.011\n",
       "teachers                     0.3150      0.064      4.937      0.000       0.190       0.440\n",
       "poor_prop                   -0.2077      0.034     -6.149      0.000      -0.274      -0.141\n",
       "n_hos_beds                   0.1760      0.071      2.467      0.014       0.036       0.316\n",
       "n_hot_rooms                 -0.0742      0.052     -1.439      0.150      -0.175       0.027\n",
       "rainfall                    -0.0033      0.008     -0.394      0.693      -0.020       0.013\n",
       "parks                       29.1089     24.177      1.204      0.229     -18.277      76.495\n",
       "avg_dist                    -0.4017      0.098     -4.118      0.000      -0.593      -0.211\n",
       "airport_YES                 -0.1524      0.211     -0.723      0.469      -0.565       0.261\n",
       "waterbody_Lake              -0.1032      0.304     -0.340      0.734      -0.698       0.492\n",
       "waterbody_Lake and River    -0.0626      0.328     -0.191      0.849      -0.705       0.580\n",
       "waterbody_River              0.2394      0.256      0.937      0.349      -0.262       0.740\n",
       "============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12706719, 0.87293281],\n",
       "       [0.39754999, 0.60245001],\n",
       "       [0.98071831, 0.01928169],\n",
       "       ...,\n",
       "       [0.28594246, 0.71405754],\n",
       "       [0.28061034, 0.71938966],\n",
       "       [0.16347219, 0.83652781]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lrs.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=clf_lrs.predict(x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_03=(clf_lrs.predict_proba(x)[:,1]>0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True, False, False,  True, False, False,\n",
       "        True,  True,  True, False,  True,  True,  True,  True, False,\n",
       "        True,  True, False,  True, False, False,  True,  True,  True,\n",
       "        True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False, False,  True,  True,  True,  True,\n",
       "       False, False, False, False,  True,  True,  True, False,  True,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False,  True,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False, False,\n",
       "       False,  True,  True, False, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True, False,\n",
       "       False, False,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True, False, False,  True, False, False, False,  True,  True,\n",
       "       False, False, False, False, False, False,  True, False,  True,\n",
       "        True,  True, False,  True,  True, False,  True,  True, False,\n",
       "       False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False, False,  True, False,  True,  True,  True,\n",
       "        True, False,  True,  True, False, False,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True, False,  True,  True,\n",
       "       False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True, False,  True, False, False, False,  True, False,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "       False,  True, False, False, False, False,  True, False,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False,  True, False,\n",
       "       False, False,  True,  True, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False, False, False,  True,  True, False, False,\n",
       "       False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False, False, False,  True, False, False,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True, False,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[196,  80],\n",
       "       [ 81, 149]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6506550218340611"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6478260869565218"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6789855072463769"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lda=LinearDiscriminantAnalysis()\n",
    "clf_lda.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lda=clf_lda.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[192,  84],\n",
       "       [ 79, 151]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y,y_pred_lda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78f5b707d86fd9281530b9fa2dbdbe1b33232c3b651a8e052360c651d4996094"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
